{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2  \n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=r\"D:\\seriestesteapp\\super_loja.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename,sep=\";\",encoding=\"latin-1\")\n",
    "df.dropna(inplace=True)\n",
    "df[['Vendas','Desconto','Lucro']] = df[['Vendas','Desconto','Lucro']].applymap(lambda k: float(str(k).replace(\",\",\".\")))\n",
    "df['Data do pedido'] = pd.to_datetime(df['Data do pedido'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/450\n",
      "3/3 [==============================] - 3s 755ms/step - loss: 15971980.0000 - mae: 2299.8108 - val_loss: 18916656.0000 - val_mae: 2237.6372\n",
      "Epoch 2/450\n",
      "3/3 [==============================] - 1s 594ms/step - loss: 15971020.0000 - mae: 2299.6025 - val_loss: 18915562.0000 - val_mae: 2237.3853\n",
      "Epoch 3/450\n",
      "3/3 [==============================] - 2s 877ms/step - loss: 15969389.0000 - mae: 2299.3630 - val_loss: 18914528.0000 - val_mae: 2237.1387\n",
      "Epoch 4/450\n",
      "3/3 [==============================] - 1s 590ms/step - loss: 15968367.0000 - mae: 2299.1255 - val_loss: 18913518.0000 - val_mae: 2236.8853\n",
      "Epoch 5/450\n",
      "3/3 [==============================] - 1s 559ms/step - loss: 15967165.0000 - mae: 2298.8787 - val_loss: 18912414.0000 - val_mae: 2236.6221\n",
      "Epoch 6/450\n",
      "3/3 [==============================] - 1s 420ms/step - loss: 15965420.0000 - mae: 2298.5452 - val_loss: 18911244.0000 - val_mae: 2236.3425\n",
      "Epoch 7/450\n",
      "3/3 [==============================] - 1s 437ms/step - loss: 15963977.0000 - mae: 2298.2161 - val_loss: 18909892.0000 - val_mae: 2236.0269\n",
      "Epoch 8/450\n",
      "3/3 [==============================] - 1s 454ms/step - loss: 15961959.0000 - mae: 2297.8625 - val_loss: 18908280.0000 - val_mae: 2235.6519\n",
      "Epoch 9/450\n",
      "3/3 [==============================] - 1s 492ms/step - loss: 15960231.0000 - mae: 2297.4971 - val_loss: 18906412.0000 - val_mae: 2235.2202\n",
      "Epoch 10/450\n",
      "3/3 [==============================] - 1s 686ms/step - loss: 15956934.0000 - mae: 2296.9475 - val_loss: 18904210.0000 - val_mae: 2234.7144\n",
      "Epoch 11/450\n",
      "3/3 [==============================] - 1s 720ms/step - loss: 15953889.0000 - mae: 2296.3547 - val_loss: 18901658.0000 - val_mae: 2234.1296\n",
      "Epoch 12/450\n",
      "3/3 [==============================] - 1s 540ms/step - loss: 15950991.0000 - mae: 2295.7275 - val_loss: 18898732.0000 - val_mae: 2233.4541\n",
      "Epoch 13/450\n",
      "3/3 [==============================] - 1s 460ms/step - loss: 15946732.0000 - mae: 2294.9414 - val_loss: 18895338.0000 - val_mae: 2232.6709\n",
      "Epoch 14/450\n",
      "3/3 [==============================] - 1s 448ms/step - loss: 15941859.0000 - mae: 2294.0835 - val_loss: 18891416.0000 - val_mae: 2231.7754\n",
      "Epoch 15/450\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 15936634.0000 - mae: 2293.0586 - val_loss: 18886916.0000 - val_mae: 2230.7510\n",
      "Epoch 16/450\n",
      "3/3 [==============================] - 1s 461ms/step - loss: 15931449.0000 - mae: 2291.8835 - val_loss: 18881854.0000 - val_mae: 2229.5999\n",
      "Epoch 17/450\n",
      "3/3 [==============================] - 1s 490ms/step - loss: 15924343.0000 - mae: 2290.5452 - val_loss: 18876146.0000 - val_mae: 2228.3035\n",
      "Epoch 18/450\n",
      "3/3 [==============================] - 1s 609ms/step - loss: 15916195.0000 - mae: 2289.0979 - val_loss: 18869668.0000 - val_mae: 2226.8354\n",
      "Epoch 19/450\n",
      "3/3 [==============================] - 2s 764ms/step - loss: 15907473.0000 - mae: 2287.3823 - val_loss: 18862480.0000 - val_mae: 2225.2100\n",
      "Epoch 20/450\n",
      "3/3 [==============================] - 1s 656ms/step - loss: 15896758.0000 - mae: 2285.3069 - val_loss: 18854408.0000 - val_mae: 2223.3884\n",
      "Epoch 21/450\n",
      "3/3 [==============================] - 1s 523ms/step - loss: 15883540.0000 - mae: 2283.0720 - val_loss: 18845360.0000 - val_mae: 2221.3672\n",
      "Epoch 22/450\n",
      "3/3 [==============================] - 1s 460ms/step - loss: 15872985.0000 - mae: 2280.7639 - val_loss: 18835062.0000 - val_mae: 2219.0798\n",
      "Epoch 23/450\n",
      "3/3 [==============================] - 1s 466ms/step - loss: 15856954.0000 - mae: 2277.9314 - val_loss: 18823670.0000 - val_mae: 2216.5664\n",
      "Epoch 24/450\n",
      "3/3 [==============================] - 1s 470ms/step - loss: 15838656.0000 - mae: 2274.7844 - val_loss: 18810974.0000 - val_mae: 2213.7886\n",
      "Epoch 25/450\n",
      "3/3 [==============================] - 1s 532ms/step - loss: 15822764.0000 - mae: 2271.2947 - val_loss: 18796674.0000 - val_mae: 2210.6777\n",
      "Epoch 26/450\n",
      "3/3 [==============================] - 1s 634ms/step - loss: 15798986.0000 - mae: 2267.0720 - val_loss: 18780800.0000 - val_mae: 2207.2502\n",
      "Epoch 27/450\n",
      "3/3 [==============================] - 1s 700ms/step - loss: 15765344.0000 - mae: 2262.5864 - val_loss: 18763242.0000 - val_mae: 2203.4868\n",
      "Epoch 28/450\n",
      "3/3 [==============================] - 2s 1s/step - loss: 15741988.0000 - mae: 2257.6460 - val_loss: 18743336.0000 - val_mae: 2199.3943\n",
      "Epoch 29/450\n",
      "3/3 [==============================] - 1s 571ms/step - loss: 15712828.0000 - mae: 2251.9998 - val_loss: 18721152.0000 - val_mae: 2194.8777\n",
      "Epoch 30/450\n",
      "3/3 [==============================] - 1s 497ms/step - loss: 15671696.0000 - mae: 2245.2114 - val_loss: 18696514.0000 - val_mae: 2189.8630\n",
      "Epoch 31/450\n",
      "3/3 [==============================] - 1s 431ms/step - loss: 15631232.0000 - mae: 2239.0354 - val_loss: 18669042.0000 - val_mae: 2184.2881\n",
      "Epoch 32/450\n",
      "3/3 [==============================] - 1s 520ms/step - loss: 15591844.0000 - mae: 2230.5042 - val_loss: 18638626.0000 - val_mae: 2178.1672\n",
      "Epoch 33/450\n",
      "3/3 [==============================] - 1s 545ms/step - loss: 15544457.0000 - mae: 2221.9763 - val_loss: 18604922.0000 - val_mae: 2171.4028\n",
      "Epoch 34/450\n",
      "3/3 [==============================] - 2s 823ms/step - loss: 15484143.0000 - mae: 2212.4958 - val_loss: 18567902.0000 - val_mae: 2164.0317\n",
      "Epoch 35/450\n",
      "3/3 [==============================] - 1s 573ms/step - loss: 15413821.0000 - mae: 2200.4363 - val_loss: 18526562.0000 - val_mae: 2156.1851\n",
      "Epoch 36/450\n",
      "3/3 [==============================] - 2s 806ms/step - loss: 15334246.0000 - mae: 2189.0354 - val_loss: 18481350.0000 - val_mae: 2147.6431\n",
      "Epoch 37/450\n",
      "3/3 [==============================] - 2s 961ms/step - loss: 15276873.0000 - mae: 2176.9502 - val_loss: 18431662.0000 - val_mae: 2138.2598\n",
      "Epoch 38/450\n",
      "3/3 [==============================] - 1s 451ms/step - loss: 15179948.0000 - mae: 2160.6143 - val_loss: 18376960.0000 - val_mae: 2128.2075\n",
      "Epoch 39/450\n",
      "3/3 [==============================] - 1s 537ms/step - loss: 15080758.0000 - mae: 2147.9155 - val_loss: 18315850.0000 - val_mae: 2117.4409\n",
      "Epoch 40/450\n",
      "3/3 [==============================] - 2s 905ms/step - loss: 14969734.0000 - mae: 2128.9426 - val_loss: 18249322.0000 - val_mae: 2105.7744\n",
      "Epoch 41/450\n",
      "3/3 [==============================] - 1s 511ms/step - loss: 14836289.0000 - mae: 2110.0835 - val_loss: 18177064.0000 - val_mae: 2093.1597\n",
      "Epoch 42/450\n",
      "3/3 [==============================] - 2s 815ms/step - loss: 14733866.0000 - mae: 2093.4087 - val_loss: 18097904.0000 - val_mae: 2080.4246\n",
      "Epoch 43/450\n",
      "3/3 [==============================] - 1s 741ms/step - loss: 14566649.0000 - mae: 2070.5586 - val_loss: 18011406.0000 - val_mae: 2066.8181\n",
      "Epoch 44/450\n",
      "3/3 [==============================] - 1s 528ms/step - loss: 14411841.0000 - mae: 2046.7671 - val_loss: 17917184.0000 - val_mae: 2052.7251\n",
      "Epoch 45/450\n",
      "3/3 [==============================] - 1s 552ms/step - loss: 14225475.0000 - mae: 2021.7688 - val_loss: 17814148.0000 - val_mae: 2038.1705\n",
      "Epoch 46/450\n",
      "3/3 [==============================] - 1s 570ms/step - loss: 14002607.0000 - mae: 1992.8347 - val_loss: 17702610.0000 - val_mae: 2023.1628\n",
      "Epoch 47/450\n",
      "3/3 [==============================] - 2s 789ms/step - loss: 13800588.0000 - mae: 1963.5360 - val_loss: 17582232.0000 - val_mae: 2007.5490\n",
      "Epoch 48/450\n",
      "3/3 [==============================] - 2s 765ms/step - loss: 13610083.0000 - mae: 1934.9708 - val_loss: 17453994.0000 - val_mae: 1990.8445\n",
      "Epoch 49/450\n",
      "3/3 [==============================] - 3s 1s/step - loss: 13317453.0000 - mae: 1901.4871 - val_loss: 17315800.0000 - val_mae: 1973.9353\n",
      "Epoch 50/450\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 13052557.0000 - mae: 1872.6333 - val_loss: 17168826.0000 - val_mae: 1959.7573\n",
      "Epoch 51/450\n",
      "3/3 [==============================] - 1s 590ms/step - loss: 12819407.0000 - mae: 1842.5344 - val_loss: 17009802.0000 - val_mae: 1947.4470\n",
      "Epoch 52/450\n",
      "3/3 [==============================] - 1s 674ms/step - loss: 12472874.0000 - mae: 1798.6719 - val_loss: 16841236.0000 - val_mae: 1936.6847\n",
      "Epoch 53/450\n",
      "3/3 [==============================] - 2s 776ms/step - loss: 12167039.0000 - mae: 1763.5109 - val_loss: 16661740.0000 - val_mae: 1927.7734\n",
      "Epoch 54/450\n",
      "3/3 [==============================] - 1s 554ms/step - loss: 11820687.0000 - mae: 1722.3475 - val_loss: 16472996.0000 - val_mae: 1919.6375\n",
      "Epoch 55/450\n",
      "3/3 [==============================] - 1s 685ms/step - loss: 11528500.0000 - mae: 1681.4672 - val_loss: 16274392.0000 - val_mae: 1911.9386\n",
      "Epoch 56/450\n",
      "3/3 [==============================] - 1s 635ms/step - loss: 11249308.0000 - mae: 1652.7417 - val_loss: 16072762.0000 - val_mae: 1904.3430\n",
      "Epoch 57/450\n",
      "3/3 [==============================] - 1s 533ms/step - loss: 10871101.0000 - mae: 1610.9187 - val_loss: 15862781.0000 - val_mae: 1897.2118\n",
      "Epoch 58/450\n",
      "3/3 [==============================] - 1s 604ms/step - loss: 10293569.0000 - mae: 1578.3613 - val_loss: 15644043.0000 - val_mae: 1890.9814\n",
      "Epoch 59/450\n",
      "3/3 [==============================] - 1s 575ms/step - loss: 10039567.0000 - mae: 1536.5817 - val_loss: 15415058.0000 - val_mae: 1884.0201\n",
      "Epoch 60/450\n",
      "3/3 [==============================] - 2s 760ms/step - loss: 9605211.0000 - mae: 1517.2097 - val_loss: 15182672.0000 - val_mae: 1877.9536\n",
      "Epoch 61/450\n",
      "3/3 [==============================] - 3s 1s/step - loss: 9223260.0000 - mae: 1490.2258 - val_loss: 14951945.0000 - val_mae: 1877.6196\n",
      "Epoch 62/450\n",
      "3/3 [==============================] - 1s 431ms/step - loss: 8920124.0000 - mae: 1485.6753 - val_loss: 14722557.0000 - val_mae: 1878.8025\n",
      "Epoch 63/450\n",
      "3/3 [==============================] - 1s 529ms/step - loss: 8290701.0000 - mae: 1449.2965 - val_loss: 14499797.0000 - val_mae: 1879.2141\n",
      "Epoch 64/450\n",
      "3/3 [==============================] - 1s 631ms/step - loss: 8312991.5000 - mae: 1453.9259 - val_loss: 14275238.0000 - val_mae: 1879.8668\n",
      "Epoch 65/450\n",
      "3/3 [==============================] - 2s 918ms/step - loss: 7816111.5000 - mae: 1438.0737 - val_loss: 14062411.0000 - val_mae: 1880.3030\n",
      "Epoch 66/450\n",
      "3/3 [==============================] - 1s 605ms/step - loss: 7704011.5000 - mae: 1444.3075 - val_loss: 13853788.0000 - val_mae: 1883.6156\n",
      "Epoch 67/450\n",
      "3/3 [==============================] - 2s 777ms/step - loss: 7386721.5000 - mae: 1443.0555 - val_loss: 13660961.0000 - val_mae: 1890.3285\n",
      "Epoch 68/450\n",
      "3/3 [==============================] - 2s 778ms/step - loss: 6858682.0000 - mae: 1418.6411 - val_loss: 13487376.0000 - val_mae: 1896.0790\n",
      "Epoch 69/450\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 6746766.5000 - mae: 1427.2653 - val_loss: 13324582.0000 - val_mae: 1900.9634\n",
      "Epoch 70/450\n",
      "3/3 [==============================] - 1s 489ms/step - loss: 6745336.0000 - mae: 1461.6884 - val_loss: 13185397.0000 - val_mae: 1904.2590\n",
      "Epoch 71/450\n",
      "3/3 [==============================] - 1s 611ms/step - loss: 6562273.5000 - mae: 1468.2285 - val_loss: 13048366.0000 - val_mae: 1907.4989\n",
      "Epoch 72/450\n",
      "3/3 [==============================] - 1s 716ms/step - loss: 6098839.0000 - mae: 1460.4746 - val_loss: 12922608.0000 - val_mae: 1909.3762\n",
      "Epoch 73/450\n",
      "3/3 [==============================] - 1s 695ms/step - loss: 6010728.0000 - mae: 1467.8256 - val_loss: 12816410.0000 - val_mae: 1909.7158\n",
      "Epoch 74/450\n",
      "3/3 [==============================] - 2s 779ms/step - loss: 6120862.5000 - mae: 1492.3458 - val_loss: 12720232.0000 - val_mae: 1909.7832\n",
      "Epoch 75/450\n",
      "3/3 [==============================] - 1s 474ms/step - loss: 5957508.5000 - mae: 1476.1825 - val_loss: 12635334.0000 - val_mae: 1909.4392\n",
      "Epoch 76/450\n",
      "3/3 [==============================] - 1s 473ms/step - loss: 5994185.0000 - mae: 1480.3468 - val_loss: 12554278.0000 - val_mae: 1908.4224\n",
      "Epoch 77/450\n",
      "3/3 [==============================] - 1s 708ms/step - loss: 5807820.5000 - mae: 1479.4125 - val_loss: 12491620.0000 - val_mae: 1905.4926\n",
      "Epoch 78/450\n",
      "3/3 [==============================] - 2s 758ms/step - loss: 5355388.0000 - mae: 1448.4491 - val_loss: 12441692.0000 - val_mae: 1902.1469\n",
      "Epoch 79/450\n",
      "3/3 [==============================] - 2s 799ms/step - loss: 5586740.5000 - mae: 1457.5215 - val_loss: 12394187.0000 - val_mae: 1898.0745\n",
      "Epoch 80/450\n",
      "3/3 [==============================] - 1s 683ms/step - loss: 5823514.0000 - mae: 1479.9454 - val_loss: 12349660.0000 - val_mae: 1893.6871\n",
      "Epoch 81/450\n",
      "3/3 [==============================] - 3s 1s/step - loss: 5851759.5000 - mae: 1455.7124 - val_loss: 12312924.0000 - val_mae: 1888.6611\n",
      "Epoch 82/450\n",
      "3/3 [==============================] - 1s 669ms/step - loss: 5143314.0000 - mae: 1421.8776 - val_loss: 12276836.0000 - val_mae: 1883.8815\n",
      "Epoch 83/450\n",
      "3/3 [==============================] - 2s 802ms/step - loss: 5465179.0000 - mae: 1413.1132 - val_loss: 12244390.0000 - val_mae: 1879.0239\n",
      "Epoch 84/450\n",
      "3/3 [==============================] - 1s 632ms/step - loss: 5560996.0000 - mae: 1441.1282 - val_loss: 12216973.0000 - val_mae: 1873.5123\n",
      "Epoch 85/450\n",
      "3/3 [==============================] - 2s 757ms/step - loss: 5121583.0000 - mae: 1398.1761 - val_loss: 12181550.0000 - val_mae: 1868.6317\n",
      "Epoch 86/450\n",
      "3/3 [==============================] - 1s 696ms/step - loss: 5176007.0000 - mae: 1392.5841 - val_loss: 12146837.0000 - val_mae: 1864.0194\n",
      "Epoch 87/450\n",
      "3/3 [==============================] - 2s 771ms/step - loss: 4959023.5000 - mae: 1371.8301 - val_loss: 12118628.0000 - val_mae: 1859.0079\n",
      "Epoch 88/450\n",
      "3/3 [==============================] - 1s 517ms/step - loss: 5129433.0000 - mae: 1409.9821 - val_loss: 12093254.0000 - val_mae: 1854.4106\n",
      "Epoch 89/450\n",
      "3/3 [==============================] - 1s 731ms/step - loss: 5217355.0000 - mae: 1345.9432 - val_loss: 12070108.0000 - val_mae: 1849.3236\n",
      "Epoch 90/450\n",
      "3/3 [==============================] - 2s 960ms/step - loss: 4843379.5000 - mae: 1333.7462 - val_loss: 12043201.0000 - val_mae: 1844.7056\n",
      "Epoch 91/450\n",
      "3/3 [==============================] - 2s 752ms/step - loss: 4511021.0000 - mae: 1315.3406 - val_loss: 12013318.0000 - val_mae: 1839.7073\n",
      "Epoch 92/450\n",
      "3/3 [==============================] - 2s 1s/step - loss: 4794119.5000 - mae: 1329.1932 - val_loss: 11990448.0000 - val_mae: 1834.3348\n",
      "Epoch 93/450\n",
      "3/3 [==============================] - 1s 498ms/step - loss: 4726291.5000 - mae: 1306.0957 - val_loss: 11953244.0000 - val_mae: 1830.2697\n",
      "Epoch 94/450\n",
      "3/3 [==============================] - 1s 638ms/step - loss: 4568233.5000 - mae: 1296.0604 - val_loss: 11927644.0000 - val_mae: 1825.9851\n",
      "Epoch 95/450\n",
      "3/3 [==============================] - 2s 764ms/step - loss: 4530193.0000 - mae: 1304.0754 - val_loss: 11886453.0000 - val_mae: 1822.5193\n",
      "Epoch 96/450\n",
      "3/3 [==============================] - 2s 977ms/step - loss: 4589782.0000 - mae: 1297.5214 - val_loss: 11851942.0000 - val_mae: 1818.7310\n",
      "Epoch 97/450\n",
      "3/3 [==============================] - 2s 803ms/step - loss: 4311906.5000 - mae: 1275.2333 - val_loss: 11815781.0000 - val_mae: 1815.2540\n",
      "Epoch 98/450\n",
      "3/3 [==============================] - 1s 575ms/step - loss: 4461714.0000 - mae: 1283.3800 - val_loss: 11782150.0000 - val_mae: 1812.0231\n",
      "Epoch 99/450\n",
      "3/3 [==============================] - 1s 506ms/step - loss: 4831826.0000 - mae: 1292.7330 - val_loss: 11757349.0000 - val_mae: 1808.6895\n",
      "Epoch 100/450\n",
      "3/3 [==============================] - 1s 537ms/step - loss: 4451269.0000 - mae: 1274.0717 - val_loss: 11733153.0000 - val_mae: 1805.6234\n",
      "Epoch 101/450\n",
      "3/3 [==============================] - 2s 773ms/step - loss: 4303518.0000 - mae: 1244.0223 - val_loss: 11710509.0000 - val_mae: 1802.3175\n",
      "Epoch 102/450\n",
      "3/3 [==============================] - 1s 674ms/step - loss: 4181392.7500 - mae: 1245.4325 - val_loss: 11681353.0000 - val_mae: 1799.4333\n",
      "Epoch 103/450\n",
      "3/3 [==============================] - 2s 787ms/step - loss: 4054271.0000 - mae: 1265.5432 - val_loss: 11650967.0000 - val_mae: 1796.2947\n",
      "Epoch 104/450\n",
      "3/3 [==============================] - 2s 750ms/step - loss: 4193637.5000 - mae: 1241.5986 - val_loss: 11629489.0000 - val_mae: 1793.0786\n",
      "Epoch 105/450\n",
      "3/3 [==============================] - 1s 513ms/step - loss: 3780055.2500 - mae: 1216.8254 - val_loss: 11609729.0000 - val_mae: 1789.8661\n",
      "Epoch 106/450\n",
      "3/3 [==============================] - 1s 606ms/step - loss: 3716289.5000 - mae: 1189.2635 - val_loss: 11585747.0000 - val_mae: 1786.8568\n",
      "Epoch 107/450\n",
      "3/3 [==============================] - 1s 650ms/step - loss: 4049963.7500 - mae: 1198.9786 - val_loss: 11559625.0000 - val_mae: 1784.2142\n",
      "Epoch 108/450\n",
      "3/3 [==============================] - 2s 934ms/step - loss: 3752354.5000 - mae: 1218.6749 - val_loss: 11537539.0000 - val_mae: 1781.1833\n",
      "Epoch 109/450\n",
      "3/3 [==============================] - 2s 794ms/step - loss: 4100705.7500 - mae: 1191.1530 - val_loss: 11515955.0000 - val_mae: 1778.6639\n",
      "Epoch 110/450\n",
      "3/3 [==============================] - 2s 856ms/step - loss: 3903424.2500 - mae: 1187.3322 - val_loss: 11497011.0000 - val_mae: 1776.0149\n",
      "Epoch 111/450\n",
      "3/3 [==============================] - 1s 501ms/step - loss: 3930169.5000 - mae: 1176.7563 - val_loss: 11485096.0000 - val_mae: 1772.9926\n",
      "Epoch 112/450\n",
      "3/3 [==============================] - 1s 717ms/step - loss: 3678069.0000 - mae: 1159.4581 - val_loss: 11467658.0000 - val_mae: 1770.2109\n",
      "Epoch 113/450\n",
      "3/3 [==============================] - 2s 861ms/step - loss: 3688217.7500 - mae: 1174.3702 - val_loss: 11454514.0000 - val_mae: 1767.2147\n",
      "Epoch 114/450\n",
      "3/3 [==============================] - 2s 832ms/step - loss: 3577845.5000 - mae: 1137.9323 - val_loss: 11435857.0000 - val_mae: 1764.3204\n",
      "Epoch 115/450\n",
      "3/3 [==============================] - 3s 2s/step - loss: 3390716.2500 - mae: 1107.6152 - val_loss: 11417053.0000 - val_mae: 1761.3552\n",
      "Epoch 116/450\n",
      "3/3 [==============================] - 1s 556ms/step - loss: 3364582.2500 - mae: 1126.5117 - val_loss: 11398934.0000 - val_mae: 1758.2429\n",
      "Epoch 117/450\n",
      "3/3 [==============================] - 2s 818ms/step - loss: 3755011.7500 - mae: 1152.8818 - val_loss: 11374262.0000 - val_mae: 1755.6205\n",
      "Epoch 118/450\n",
      "3/3 [==============================] - 2s 882ms/step - loss: 3599127.0000 - mae: 1131.0637 - val_loss: 11345099.0000 - val_mae: 1753.1514\n",
      "Epoch 119/450\n",
      "3/3 [==============================] - 2s 960ms/step - loss: 3318709.0000 - mae: 1103.2517 - val_loss: 11318437.0000 - val_mae: 1750.2838\n",
      "Epoch 120/450\n",
      "3/3 [==============================] - 2s 889ms/step - loss: 3270845.0000 - mae: 1110.1362 - val_loss: 11288241.0000 - val_mae: 1747.7076\n",
      "Epoch 121/450\n",
      "3/3 [==============================] - 1s 515ms/step - loss: 3461677.0000 - mae: 1117.3171 - val_loss: 11259565.0000 - val_mae: 1744.9773\n",
      "Epoch 122/450\n",
      "3/3 [==============================] - 1s 743ms/step - loss: 3469383.2500 - mae: 1128.9933 - val_loss: 11237381.0000 - val_mae: 1741.9297\n",
      "Epoch 123/450\n",
      "3/3 [==============================] - 2s 835ms/step - loss: 3043592.7500 - mae: 1051.7222 - val_loss: 11224225.0000 - val_mae: 1738.7080\n",
      "Epoch 124/450\n",
      "3/3 [==============================] - 2s 763ms/step - loss: 3279421.7500 - mae: 1109.2433 - val_loss: 11202031.0000 - val_mae: 1735.3337\n",
      "Epoch 125/450\n",
      "3/3 [==============================] - 1s 649ms/step - loss: 3149978.2500 - mae: 1071.2466 - val_loss: 11184938.0000 - val_mae: 1732.4689\n",
      "Epoch 126/450\n",
      "3/3 [==============================] - 2s 840ms/step - loss: 3595725.0000 - mae: 1114.6611 - val_loss: 11169447.0000 - val_mae: 1732.2833\n",
      "Epoch 127/450\n",
      "3/3 [==============================] - 1s 542ms/step - loss: 3021974.7500 - mae: 1042.7882 - val_loss: 11155325.0000 - val_mae: 1733.4639\n",
      "Epoch 128/450\n",
      "3/3 [==============================] - 2s 888ms/step - loss: 3054709.5000 - mae: 1010.8476 - val_loss: 11147972.0000 - val_mae: 1733.8667\n",
      "Epoch 129/450\n",
      "3/3 [==============================] - 2s 1s/step - loss: 3250748.2500 - mae: 1058.2983 - val_loss: 11131923.0000 - val_mae: 1735.0004\n",
      "Epoch 130/450\n",
      "3/3 [==============================] - 2s 832ms/step - loss: 3036479.0000 - mae: 1026.7329 - val_loss: 11117798.0000 - val_mae: 1736.1316\n",
      "Epoch 131/450\n",
      "3/3 [==============================] - 2s 1s/step - loss: 2848426.5000 - mae: 1028.7192 - val_loss: 11100608.0000 - val_mae: 1738.6808\n",
      "Epoch 132/450\n",
      "3/3 [==============================] - 1s 609ms/step - loss: 2717632.5000 - mae: 1016.0250 - val_loss: 11083847.0000 - val_mae: 1741.5856\n",
      "Epoch 133/450\n",
      "3/3 [==============================] - 2s 825ms/step - loss: 2994759.7500 - mae: 1053.4165 - val_loss: 11067334.0000 - val_mae: 1745.1584\n",
      "Epoch 134/450\n",
      "3/3 [==============================] - 2s 916ms/step - loss: 2579988.2500 - mae: 999.8233 - val_loss: 11057357.0000 - val_mae: 1747.2639\n",
      "Epoch 135/450\n",
      "3/3 [==============================] - 2s 933ms/step - loss: 2665421.5000 - mae: 1008.9312 - val_loss: 11044729.0000 - val_mae: 1749.8496\n",
      "Epoch 136/450\n",
      "3/3 [==============================] - 2s 787ms/step - loss: 2829639.0000 - mae: 1023.1340 - val_loss: 11040005.0000 - val_mae: 1751.0984\n",
      "Epoch 137/450\n",
      "3/3 [==============================] - 1s 514ms/step - loss: 2498175.0000 - mae: 973.6948 - val_loss: 11039182.0000 - val_mae: 1751.7552\n",
      "Epoch 138/450\n",
      "3/3 [==============================] - 1s 681ms/step - loss: 2642700.2500 - mae: 964.6534 - val_loss: 11041626.0000 - val_mae: 1752.5474\n",
      "Epoch 139/450\n",
      "3/3 [==============================] - 2s 757ms/step - loss: 2565626.2500 - mae: 983.0381 - val_loss: 11042920.0000 - val_mae: 1753.3623\n",
      "Epoch 140/450\n",
      "3/3 [==============================] - 1s 734ms/step - loss: 2470225.7500 - mae: 943.2415 - val_loss: 11042969.0000 - val_mae: 1754.8228\n",
      "Epoch 141/450\n",
      "3/3 [==============================] - 2s 786ms/step - loss: 2541210.5000 - mae: 952.1541 - val_loss: 11029730.0000 - val_mae: 1758.2910\n",
      "Epoch 142/450\n",
      "3/3 [==============================] - 1s 685ms/step - loss: 2444028.2500 - mae: 926.5953 - val_loss: 11020933.0000 - val_mae: 1761.5292\n",
      "Epoch 143/450\n",
      "3/3 [==============================] - 1s 535ms/step - loss: 2538913.2500 - mae: 941.3455 - val_loss: 11014970.0000 - val_mae: 1763.8972\n",
      "Epoch 144/450\n",
      "3/3 [==============================] - 1s 548ms/step - loss: 2356995.0000 - mae: 940.9135 - val_loss: 11009930.0000 - val_mae: 1765.5275\n",
      "Epoch 145/450\n",
      "3/3 [==============================] - 2s 751ms/step - loss: 2418703.2500 - mae: 941.7905 - val_loss: 11003162.0000 - val_mae: 1767.5559\n",
      "Epoch 146/450\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1890826.5000 - mae: 852.9293"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_keep = ['Modo de envio', 'Segmento', 'Cidade', 'Estado', 'País/Região', 'Região',\n",
    "                   'Categoria', 'Sub-categoria', 'Vendas', 'Quantidade', 'Desconto', 'Lucro']\n",
    "df_filtered = df[columns_to_keep]\n",
    "\n",
    "\n",
    "X = df_filtered.drop(columns=['Vendas'])\n",
    "y = df_filtered['Vendas']\n",
    "\n",
    "\n",
    "categorical_columns = ['Modo de envio', 'Segmento', 'Cidade', 'Estado', 'País/Região', 'Região',\n",
    "                       'Categoria', 'Sub-categoria']\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "X_encoded = encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "encoded_columns = encoder.get_feature_names_out(input_features=categorical_columns)\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_columns, index=X.index)\n",
    "\n",
    "X = pd.concat([X.drop(columns=categorical_columns), X_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "modelo = Sequential()\n",
    "modelo.add(Dense(units=1512, activation='relu', input_dim=X_scaled.shape[1], kernel_regularizer=l2(0.001))) \n",
    "modelo.add(Dropout(0.4))\n",
    "modelo.add(Dense(units=256, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "modelo.add(Dropout(0.4))\n",
    "modelo.add(Dense(units=128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "modelo.add(Dense(units=64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "modelo.add(Dense(units=32, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "modelo.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "modelo.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=r'D:\\seriestesteapp\\logs', histogram_freq=1, write_graph=True, write_images=True)\n",
    "\n",
    "\n",
    "resultado = modelo.fit(X_train, y_train, epochs=450, batch_size=64, verbose=1, validation_split=0.2, callbacks=[tensorboard])\n",
    "\n",
    "\n",
    "previsoes = modelo.predict(X_test)\n",
    "\n",
    "\n",
    "for index, valor_real in enumerate(y_test):\n",
    "    previsao = previsoes[index][0]\n",
    "    print(f'Índice: {index}, Valor Real: {valor_real:.2f}, Previsão: {previsao:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
